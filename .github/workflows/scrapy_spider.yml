name: Run Scrapy Spider

# Controls when the action will run
on:
  schedule:
    # Runs every 24 hours
    - cron: "0 0 * * *"
  workflow_dispatch: # Allows manual triggering from the Actions tab

jobs:
  run-spider:
    runs-on: ubuntu-latest

    services:
      splash:
        image: scrapinghub/splash
        options: --privileged --name splash -p 8050:8050

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.x"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run Scrapy Spider
        env:
          SPLASH_URL: http://localhost:8050
          API_KEY: ${{ secrets.API_KEY }}
          DOMAIN: ${{ secrets.DOMAIN }}
          MAILJET_API_KEY: ${{ secrets.MAILJET_API_KEY}}
          MAILJET_API_SECRET: ${{ secrets.MAILJET_API_SECRET}}
          SMTP_PASSWORD: ${{secrets.SMTP_PASSWORD}}

        run: |
          cd studentbostad_scraper/studentbostad_scraper/spiders
          scrapy crawl spider
